---
title: "Chapter 13.06: Cross-Entropy and KL"
weight: 13006
---
We introduce cross-entropy as a further information-theoretic concept and discuss the connection between entropy, cross-entropy, and Kullback-Leibler divergence.

<!--more-->

### Lecture video

{{< video id="vtS6h0UYs4E" >}}

### Lecture slides

{{< pdfjs file="https://github.com/slds-lmu/lecture_sl/raw/main/slides-pdf/slides-info-cross-entropy-kld.pdf" >}}
