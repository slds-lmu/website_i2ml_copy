<!DOCTYPE html>
<html><head>
	<meta name="generator" content="Hugo 0.91.2" />
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="/website_i2ml_copy/css/style.css">


<title>Introduction to Machine Learning (I2ML)</title>


<link rel="apple-touch-icon" sizes="180x180" href="/website_i2ml_copy/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/website_i2ml_copy/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/website_i2ml_copy/favicon-16x16.png">
<link rel="manifest" href="/website_i2ml_copy/site.webmanifest">
<link rel="mask-icon" href="/website_i2ml_copy/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">

</head><body>
<img id="logo" src="/website_i2ml_copy/i2ml.svg" />

<div id="nav-border" class="container">
    <nav id="nav" class="nav justify-content-center">
        
        <a class="nav-link" href="/website_i2ml_copy">
        
        Home
        </a>
        
        <a class="nav-link" href="/website_i2ml_copy/chapters/">
        
        Chapters
        </a>
        
        <a class="nav-link" href="/website_i2ml_copy/appendix/">
        
        Appendix
        </a>
        
        <a class="nav-link" href="/website_i2ml_copy/exercises/">
        
        Exercises
        </a>
        
        <a class="nav-link" href="/website_i2ml_copy/references/">
        
        References
        </a>
        
        <a class="nav-link" href="/website_i2ml_copy/team/">
        
        Team
        </a>
        
    </nav>
</div><div id="content" class="container">
<h1>Introduction to Machine Learning (I2ML)</h1>
<p>This website offers an open and free introductory course on (supervised) machine learning. The course is constructed holistically and as self-contained as possible, in order to cover most relevant areas of supervised ML. While the introductory parts are more aimed at a practical and operational understanding of the covered algorithms and models, we also include sound theoretical foundations and proofs in more advanced sections in order to teach ML theory as self-contained and precise as possible.</p>
<p>It can either be taken as an introductory undergraduate course early on - if you skip the more advanced sections - or as an introductory graduate-level course for Master&rsquo;s level students.</p>
<p>One general, important goal of the course - on top of clearly explaining the most popular ML algorithms - is to clearly demonstrate the fundamental building blocks behind ML, instead of introducing &ldquo;yet another algorithm, with yet another differently named concept&rdquo;. We discuss, compare and contrast risk minimization, statistical parameter estimation, the Bayesian viewpoint and information theory and demonstrate that all of these are equally valid entry points to ML - which often (confusingly) talk about the same thing with different terminology. Being able to understand these similarities and enabling to mentally switch perspectives when needed is a major goal of this course.</p>
<p>If you want to learn more about this course, please (1) read the outline further below and (2) read the section on prerequisites</p>
<p>Later on, please note: (1) The course uses a unified mathematical notation. We provide cheat sheets to summarize the most important symbols and concepts. (2) Most sections already contain quizzes, coding demos, and exercises with worked-out solutions to enable self-study as much as possible.</p>
<p>What this course does not cover - in order to not have its scope grow completely out of hand: (1) Neural networks and deep learning. We are currently working on a similar repo / page for that, which builds upon this course. (2) An in-depth coverage of optimization. We might publish a course on that at some point, but this is currently lower priority.</p>
<p>While most of the course is on a conceptual, programming language-independent level - which is by design - we offer a large variety of applied exercises in R, often using the mlr3 package and its corresponding universe. We are working on offering the exercises in python as well.</p>
<p>The course material is developed in a <a href="https://github.com/compstat-lmu/lecture_i2ml">public GitHub repository</a>. You can find the changelog <a href="https://github.com/compstat-lmu/lecture_i2ml/blob/master/CHANGELOG.md">here</a>.</p>
<p>If you love teaching ML and have free resources available, please consider joining the team and email us now! (<a href="mailto:bernd.bischl@stat.uni-muenchen.de">bernd.bischl@stat.uni-muenchen.de</a> or <a href="mailto:ludwig.bothmann@stat.uni-muenchen.de">ludwig.bothmann@stat.uni-muenchen.de</a>)</p>



<hr />




<div class="chapter_overview" id="index_chapters">
<ul class="list-unstyled">


<li><a class="title" href="/website_i2ml_copy/chapters/01_ml_basics/">Chapter 1: ML Basics</a>

<ul>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/01_ml_basics/01-01-what_is_ml/">Chapter 01.01: What is ML?</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/01_ml_basics/01-02-data/">Chapter 01.02: Data</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/01_ml_basics/01-03-tasks/">Chapter 01.03: Tasks</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/01_ml_basics/01-04-models-parameters/">Chapter 01.04: Models and Parameters</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/01_ml_basics/01-05-learner/">Chapter 01.05: Learner</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/01_ml_basics/01-06-riskminimization/">Chapter 01.06: Losses and Risk Minimization</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/01_ml_basics/01-07-optimization/">Chapter 01.07: Optimization</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/01_ml_basics/01-08-learnercomponents-hro/">Chapter 01.08: Components of a Learner</a></li>
  
</ul>

</li>

<li><a class="title" href="/website_i2ml_copy/chapters/02_supervised_regression/">Chapter 2: Supervised Regression</a>

<ul>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/02_supervised_regression/02-01-losses/">Chapter 02.01: Loss Functions for Regression</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/02_supervised_regression/02-02-linearmodel/">Chapter 02.02: Linear Regression Models</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/02_supervised_regression/02-03-polynomials/">Chapter 02.03: Polynomial Regression Models</a></li>
  
</ul>

</li>

<li><a class="title" href="/website_i2ml_copy/chapters/03_supervised_classification/">Chapter 03: Supervised Classification</a>

<ul>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/03_supervised_classification/03-01-tasks/">Chapter 03.01: Classification Tasks</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/03_supervised_classification/03-02-classification-basicdefs/">Chapter 03.02: Basic Definitions</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/03_supervised_classification/03-03-classification-linear/">Chapter 03.03: Linear Classifiers</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/03_supervised_classification/03-04-classification-logistic/">Chapter 03.04: Logistic Regression</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/03_supervised_classification/03-05-classification-discranalysis/">Chapter 03.05: Discriminant Analysis</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/03_supervised_classification/03-06-classification-naivebayes/">Chapter 03.06: Naive Bayes</a></li>
  
</ul>

</li>

<li><a class="title" href="/website_i2ml_copy/chapters/04_evaluation/">Chapter 04: Performance Evaluation</a>

<ul>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/04_evaluation/04-01-generalization-error/">Chapter 04.01: Generalization Error</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/04_evaluation/04-02-measures-regression/">Chapter 04.02: Measures Regression</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/04_evaluation/04-03-train/">Chapter 04.03: Training Error</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/04_evaluation/04-04-test/">Chapter 04.04: Test Error</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/04_evaluation/04-05-overfitting-underfitting/">Chapter 04.05: Overfitting &amp; Underfitting</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/04_evaluation/04-06-resampling-1/">Chapter 04.06: Resampling 1</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/04_evaluation/04-07-resampling-2/">Chapter 04.07: Resampling 2</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/04_evaluation/04-08-measures-classification/">Chapter 04.08: Measures Classification</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/04_evaluation/04-09-rocbasics/">Chapter 04.09: ROC Basics</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/04_evaluation/04-10-roccurves/">Chapter 04.10: ROC Curves</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/04_evaluation/04-11-partialauc-mcauc/">Chapter 04.11: Partial AUC &amp; Multi-Class AUC</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/04_evaluation/04-12-prcurves/">Chapter 04.12: Precision-Recall Curves</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/04_evaluation/04-13-auc-mwu/">Chapter 04.13: AUC &amp; Mann-Whitney-U Test</a></li>
  
</ul>

</li>

<li><a class="title" href="/website_i2ml_copy/chapters/05_knn/">Chapter 05: k-Nearest Neighbors (k-NN)</a>

<ul>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/05_knn/05-01-knn/">Chapter 05.01: k-Nearest Neighbors (k-NN)</a></li>
  
</ul>

</li>

<li><a class="title" href="/website_i2ml_copy/chapters/06_trees/">Chapter 06: Classification and Regression Trees (CART)</a>

<ul>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/06_trees/06-01-intro/">Chapter 06.01: Introduction</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/06_trees/06-02-splitcriteria/">Chapter 06.02: Splitting Criteria</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/06_trees/06-03-treegrowing/">Chapter 06.03: Growing a Tree</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/06_trees/06-04-splitcomputation/">Chapter 06.04: Computational Aspects of Finding Splits</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/06_trees/06-05-stoppingpruning/">Chapter 06.05: Stopping Criteria &amp; Pruning</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/06_trees/06-06-discussion/">Chapter 06.06: Discussion</a></li>
  
</ul>

</li>

<li><a class="title" href="/website_i2ml_copy/chapters/07_forests/">Chapter 07: Random Forests</a>

<ul>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/07_forests/07-01-bagging/">Chapter 07.01: Bagging Ensembles</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/07_forests/07-02-intro/">Chapter 07.02: Introduction</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/07_forests/07-03-benchmark/">Chapter 07.03: Benchmarking Trees, Forests, and Bagging k-NN</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/07_forests/07-04-featureimportance/">Chapter 07.04: Feature Importance</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/07_forests/07-05-proximities/">Chapter 07.05: Proximities</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/07_forests/07-06-discussion/">Chapter 07.06: Discussion</a></li>
  
</ul>

</li>

<li><a class="title" href="/website_i2ml_copy/chapters/08_tuning/">Chapter 08: Tuning</a>

<ul>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/08_tuning/08-01-intro/">Chapter 08.01: Introduction</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/08_tuning/08-02-tuning-tuningproblem/">Chapter 08.02: Problem Definition</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/08_tuning/08-03-basicalgos/">Chapter 08.03: Basic Techniques</a></li>
  
</ul>

</li>

<li><a class="title" href="/website_i2ml_copy/chapters/09_nested_resampling/">Chapter 09: Nested Resampling</a>

<ul>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/09_nested_resampling/09-01-nestedintro/">Chapter 09.01: Motivation</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/09_nested_resampling/09-02-trainvalidtest/">Chapter 09.02: Training - Validation - Testing</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/09_nested_resampling/09-03-nestedresampling/">Chapter 09.03: Nested Resampling</a></li>
  
</ul>

</li>

<li><a class="title" href="/website_i2ml_copy/chapters/10_mlr3/">Chapter 10: mlr3</a>

<ul>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/10_mlr3/10-01-intro/">Chapter 10.01: Intro to mlr3</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/10_mlr3/10-02-resampling/">Chapter 10.02: Resampling with mlr3</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/10_mlr3/10-03-tuning/">Chapter 10.03: Tuning with mlr3</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/10_mlr3/10-04-pipelines/">Chapter 10.04: Pipelines with mlr3</a></li>
  
</ul>

</li>

<li><a class="title" href="/website_i2ml_copy/chapters/11_advriskmin/">Chapter 11: Advanced Risk Minimization</a>

<ul>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/11_advriskmin/11-01-risk-minimizer/">Chapter 11.01: Risk Minimizers</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/11_advriskmin/11-02-pseudo-residuals/">Chapter 11.02: Pseudo-Residuals</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/11_advriskmin/11-03-regression-l2/">Chapter 11.03: L2 Loss</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/11_advriskmin/11-04-regression-l1/">Chapter 11.04: L1 Loss</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/11_advriskmin/11-05-regression-further-losses/">Chapter 11.05: Advanced Regression Losses</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/11_advriskmin/11-06-classification-01/">Chapter 11.06: 0-1 Loss</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/11_advriskmin/11-07-classification-bernoulli/">Chapter 11.07: Bernoulli Loss</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/11_advriskmin/11-08-classification-brier/">Chapter 11.08: Brier Score</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/11_advriskmin/11-09-classification-further-losses/">Chapter 11.09: Advanced Classification Losses</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/11_advriskmin/11-10-max-likelihood-l2/">Chapter 11.10: Maximum Likelihood Estimation vs Empirical Risk Minimization I</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/11_advriskmin/11-11-max-likelihood-other/">Chapter 11.11: Maximum Likelihood Estimation vs Empirical Risk Minimization II</a></li>
  
</ul>

</li>

<li><a class="title" href="/website_i2ml_copy/chapters/12_multiclass/">Chapter 12: Multiclass Classification</a>

<ul>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/12_multiclass/12-01-losses/">Chapter 12.01: Multiclass Classification and Losses</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/12_multiclass/12-02-softmax-regression/">Chapter 12.02: Softmax Regression</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/12_multiclass/12-03-binary-reduction/">Chapter 12.03: One-vs-One and One-vs-Rest</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/12_multiclass/12-04-codebooks/">Chapter 12.04: Designing Codebooks and ECOC</a></li>
  
</ul>

</li>

<li><a class="title" href="/website_i2ml_copy/chapters/13_information_theory/">Chapter 13: Information Theory</a>

<ul>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/13_information_theory/13-01-entropy/">Chapter 13.01: Entropy</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/13_information_theory/13-02-diffent/">Chapter 13.02: Differential Entropy</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/13_information_theory/13-03-kl/">Chapter 13.03: Kullback-Leibler Divergence</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/13_information_theory/13-04-sourcecoding/">Chapter 13.04: Entropy and Optimal Code Length</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/13_information_theory/13-05-cross-entropy-kld/">Chapter 13.05: Cross-Entropy, KL and Source Coding</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/13_information_theory/13-06-ml/">Chapter 13.06: Information Theory for Machine Learning</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/13_information_theory/13-07-mutual-info/">Chapter 13.07: Joint Entropy and Mutual Information</a></li>
  
</ul>

</li>

<li><a class="title" href="/website_i2ml_copy/chapters/14_cod/">Chapter 14: Curse of Dimensionality</a>

<ul>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/14_cod/14-01-cod/">Chapter 14.01: Curse of Dimensionality</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/14_cod/14-02-cod-examples/">Chapter 14.02: Curse of Dimensionality - Examples</a></li>
  
</ul>

</li>

<li><a class="title" href="/website_i2ml_copy/chapters/15_hypospaces_capacity/">Chapter 15: Hypothesis Spaces</a>

<ul>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/15_hypospaces_capacity/15-01-hypospaces-examples/">Chapter 15.01: Examples of Hypothesis Spaces</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/15_hypospaces_capacity/15-02-hypospaces-capacity-overfitting/">Chapter 15.02: Capacity and Overfitting</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/15_hypospaces_capacity/15-03-complexity/">Chapter 15.03: PAC Learning and VC Dimension</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/15_hypospaces_capacity/15-04-bias-variance-decomposition/">Chapter 15.04: Bias-Variance Decomposition</a></li>
  
</ul>

</li>

<li><a class="title" href="/website_i2ml_copy/chapters/16_regularization/">Chapter 16: Regularization</a>

<ul>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/16_regularization/16-01-regu-intro/">Chapter 16.01: Introduction to Regularization</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/16_regularization/16-02-l1l2/">Chapter 16.02: Lasso and Ridge Regression</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/16_regularization/16-03-l1vsl12/">Chapter 16.03: Lasso vs Ridge Regression</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/16_regularization/16-04-enetlogreg/">Chapter 16.04: Elastic Net and Regularization for GLMs</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/16_regularization/16-05-underdetermined/">Chapter 16.05: Regularization for Underdetermined Problems</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/16_regularization/16-06-l0/">Chapter 16.06: L0 Regularization</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/16_regularization/16-07-nonlin-bayes/">Chapter 16.07: Regularization in NonLinear Models and Bayesian Priors</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/16_regularization/16-08-geom-l2-wdecay/">Chapter 16.08: Geometric Analysis of L2 Regularization and Weight Decay</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/16_regularization/16-09-geom-l1/">Chapter 16.09: Geometric Analysis of L1 Regularization</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/16_regularization/16-10-early-stopping/">Chapter 16.10: Early Stopping</a></li>
  
</ul>

</li>

<li><a class="title" href="/website_i2ml_copy/chapters/17_linear_svm/">Chapter 17: Linear Support Vector Machines</a>

<ul>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/17_linear_svm/17-01-hard-margin/">Chapter 17.01: Linear Hard Margin SVM</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/17_linear_svm/17-02-hard-margin-dual/">Chapter 17.02: Hard Margin SVM Dual</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/17_linear_svm/17-03-soft-margin/">Chapter 17.03: Soft Margin SVM</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/17_linear_svm/17-04-erm/">Chapter 17.04: SVMs and Empirical Risk Minimization</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/17_linear_svm/17-05-optimization/">Chapter 17.05: SVM Training</a></li>
  
</ul>

</li>

<li><a class="title" href="/website_i2ml_copy/chapters/18_nonlinear_svm/">Chapter 18: Nonlinear Support Vector Machines</a>

<ul>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/18_nonlinear_svm/18-01-featuregen/">Chapter 18.01: Feature Generation for Nonlinear Separation</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/18_nonlinear_svm/18-02-kernel-trick/">Chapter 18.02: The Kernel Trick</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/18_nonlinear_svm/18-03-kernel-poly/">Chapter 18.03: The Polynomial Kernel</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/18_nonlinear_svm/18-04-rkhs-repr/">Chapter 18.04: Reproducing Kernel Hilbert Space and Representer Theorem</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/18_nonlinear_svm/18-05-kernel-rbf/">Chapter 18.05: The Gaussian RBF Kernel</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/18_nonlinear_svm/18-06-model-sel/">Chapter 18.06: SVM Model Selection</a></li>
  
</ul>

</li>

<li><a class="title" href="/website_i2ml_copy/chapters/19_gaussian_processes/">Chapter 19: Gaussian Processes</a>

<ul>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/19_gaussian_processes/19-01-bayes-lm/">Chapter 19.01: The Bayesian Linear Model</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/19_gaussian_processes/19-02-basic/">Chapter 19.02: Gaussian Processes</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/19_gaussian_processes/19-03-covariance/">Chapter 19.03: Covariance Functions for GPs</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/19_gaussian_processes/19-04-prediction/">Chapter 19.04: Gaussian Process Prediction</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/19_gaussian_processes/19-05-training/">Chapter 19.05: Gaussian Process Training</a></li>
  
</ul>

</li>

<li><a class="title" href="/website_i2ml_copy/chapters/20_boosting/">Chapter 20: Boosting</a>

<ul>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/20_boosting/20-01-intro-adaboost/">Chapter 20.01: Introduction to Boosting / AdaBoost</a></li>
  
  <li><a class="title" href="/website_i2ml_copy/chapters/20_boosting/20-02-gradient-boosting-concept/">Chapter 20.02: Boosting Concept</a></li>
  
</ul>

</li>

</ul>
</div>





<div class="chapter_overview" id="index_appendix">
<ul class="list-unstyled">


<li><a class="title" href="/website_i2ml_copy/appendix/01_cheat_sheets/">Cheat Sheets</a></li>

<li><a class="title" href="/website_i2ml_copy/appendix/02_errata/">Errata</a></li>


</ul>
</div>





<div class="chapter_overview" id="index_appendix">
<ul class="list-unstyled">
<li><a class="title" href="/website_i2ml_copy/exercises/">Exercises</a></li>
</ul>
</div>


        </div><footer class="bg-light text-center text-lg-start fixed-bottom">
<ul class="list-inline text-center">
  <li class="list-inline-item">© 2021 Course Creator</li>
  
  <li class="list-inline-item"><a class="nav-link" href="https://github.com/slds-lmu/lecture_i2ml" target="_blank">Course content</a></li>
  
  <li class="list-inline-item"><a class="nav-link" href="/website_i2ml_copy" target="_blank">Main Course Website</a></li>
  
  <li class="list-inline-item"><a class="nav-link" href="https://github.com/slds-lmu/i2ml" target="_blank">Website source code</a></li>
  
</ul>
</footer>

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      ignoreHtmlClass: ['quizdown']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</body>
</html>
